# ------------------------------------------------------------------------------
# ğŸ“„ Config File: run_duplicates_config.yaml
# ğŸ§© Module: Duplicates (M04)
# ğŸ“Œ Purpose: Detects and handles duplicate rows based on configured logic.
# ------------------------------------------------------------------------------
# This module can flag or remove duplicates depending on the `mode` setting.
# ------------------------------------------------------------------------------

# ğŸ“¥ Execution context
notebook: true
run_id: "removal_run"
logging: "auto"             # Options: 'on', 'off', or 'auto'

# ğŸ” Duplicate detection settings
duplicates:
  run: true

  # ğŸ¯ Target subset (null = use all columns)
  subset_columns: ['tag_id', 'species', 'capture_date']

  # ğŸ§­ Deduplication logic
  keep: 'first'          # Options: 'first', 'last', or False (to drop all duplicates)
  mode: 'remove'           # Options: 'remove', 'flag'

  # ğŸ“‚ Input source
  input_path: "exports/joblib/{run_id}/{run_id}_m02_certified.joblib"

  # âš™ï¸ Operational settings (required by pipeline)
  settings:
    checkpoint:
      run: true
      checkpoint_path: "exports/joblib/{run_id}/{run_id}_m04__dupes_checkpoint.joblib"

    export: true
    export_path: "exports/reports/duplicates/duplicates_report.xlsx"
    as_csv: false          # false = single XLSX report with multiple sheets

    show_inline: true

    plotting:
      run: true
      save_dir: "exports/plots/duplicates/"

  # ğŸ§¼ Optional preview cleanup for schema-variant files
  preview_drop_columns:
    - "timestamp"
    - "script_name"
    - "user"