"""
üìä Module: data_diag.py

Config-driven data profiling for pandas DataFrames.

Generates a structured summary of a dataset's characteristics including:
- Schema overview with audit remarks
- Missing value statistics
- Duplicate row counts and previews
- High cardinality detection
- Memory usage and shape
- Descriptive statistics and sample previews

Designed for use in diagnostics modules or interactive QA notebooks.
Supports export-ready output and optional validation metadata.
"""
import pandas as pd
from datetime import datetime
import getpass
import logging

def generate_data_profile(df: pd.DataFrame, high_cardinality_threshold: int = 10, max_rows: int = 5, quality_checks: dict = None, **kwargs):
    """
    Generates a structured profile of a DataFrame with optional audit metadata.

    Args:
        df (pd.DataFrame): The DataFrame to profile.
        high_cardinality_threshold (int): Threshold for flagging high-cardinality object columns.
        max_rows (int): Number of rows to include in preview tables.
        quality_checks (dict, optional): Includes skew threshold and expected dtypes.
        **kwargs: Additional parameters passed through (currently unused).

    Returns:
        dict: A dictionary with 'for_display' and 'for_export' keys containing DataFrames.
    """
    if quality_checks is None: 
        quality_checks = {}
    skew_threshold = quality_checks.get("skew_threshold", 2.0)
    expected_dtypes = quality_checks.get("expected_dtypes", {})
    
    numeric_cols = df.select_dtypes(include='number')
    skews = numeric_cols.skew().abs()
    
    # Schema summary: dtype and uniqueness
    schema_df = pd.DataFrame({
        "Column": df.columns,
        "Dtype": df.dtypes.astype(str),
        "Unique Values": df.nunique()
    })

    # Audit remarks: unexpected types and skew
    audit_remarks = []
    for i, row in schema_df.iterrows():
        col = row['Column']
        remarks = []
        # Check 1: Unexpected Dtype
        if col in expected_dtypes and row['Dtype'] != expected_dtypes[col]:
            remarks.append(f"‚ö†Ô∏è Unexpected Type (Expected: {expected_dtypes[col]})")
        
        # Check 2: High Skew
        if col in skews and skews[col] > skew_threshold:
            remarks.append(f"‚ö†Ô∏è High Skew ({skews[col]:.2f})")
        
        # If no remarks were raised, the status is OK.
        if not remarks:
            audit_remarks.append("‚úÖ OK")
        else:
            # Join multiple remarks with a line break for display
            audit_remarks.append("<br>".join(remarks))
            
    # Renamed column for clarity
    schema_df['Audit Remarks'] = audit_remarks

    # Merge missing value stats
    missing_counts = df.isnull().sum().reset_index(name="Missing Count")
    missing_counts.columns = ["Column", "Missing Count"]
    missing_counts["Missing %"] = ((missing_counts["Missing Count"] / len(df)) * 100).round(2)
    schema_df = pd.merge(schema_df, missing_counts, on="Column", how="left")
    schema_df["Missing Count"] = schema_df["Missing Count"].fillna(0).astype(int)

    # Identify high-cardinality object columns
    high_card_df = schema_df[
        (schema_df["Dtype"] == "object") & 
        (schema_df["Unique Values"] > high_cardinality_threshold)
    ][["Column", "Unique Values"]].sort_values("Unique Values", ascending=False).reset_index(drop=True)

    dup_count = df.duplicated().sum()
    dup_summary_df = pd.DataFrame([{"Duplicate Rows": dup_count, "Duplicate %": (dup_count / len(df) * 100).round(2) if len(df) > 0 else 0}])
    duplicated_rows_df = df[df.duplicated(keep=False)].head(max_rows)
    describe_df = numeric_cols.describe().T
    describe_df['skew'] = numeric_cols.skew()
    describe_df['kurtosis'] = numeric_cols.kurt()
    describe_df = describe_df.reset_index().rename(columns={"index": "Metric"})
    sample_head_df = df.head(max_rows)
    shape_df = pd.DataFrame([{"Rows": df.shape[0], "Columns": df.shape[1]}])
    mem_mb = df.memory_usage(deep=True).sum() / (1024**2)
    mem_df = pd.DataFrame([{"Memory Usage": f"{mem_mb:.2f} MB"}])

    profile_for_display = {
        "schema": schema_df,
        "high_cardinality": high_card_df,
        "shape": shape_df,
        "memory_usage": mem_df,
        "duplicates_summary": dup_summary_df,
        "duplicated_rows": duplicated_rows_df,
        "describe": describe_df,
        "sample_head": sample_head_df
    }
    
    profile_for_export = {k: v.copy() for k, v in profile_for_display.items() if isinstance(v, pd.DataFrame)}
    
    return {
        "for_display": profile_for_display,
        "for_export": profile_for_export
    }


def run_data_profile(df: pd.DataFrame, config: dict = {}, **kwargs):
    """
    Orchestrates data profiling using config-driven settings.

    Args:
        df (pd.DataFrame): Input DataFrame to profile.
        config (dict): YAML-style config with nested profile > settings structure.
        **kwargs: Additional settings forwarded to the generator.

    Returns:
        dict: Structured profile output containing display and export blocks.
    """
    profile_cfg = config.get("profile", {})
    return generate_data_profile(df, **profile_cfg.get("settings", {}))
