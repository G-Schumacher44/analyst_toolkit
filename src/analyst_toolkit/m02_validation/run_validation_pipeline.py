"""
ðŸš€ Module: run_validation_pipeline.py

Runner script for the M02 Validation module of the Analyst Toolkit.

This orchestrator handles configuration resolution, logging setup, optional
data loading, validation execution, export of rule-check results, and inline
dashboard display. It supports both standalone use in notebooks and integration
with the full pipeline runner.

Supports schema, dtype, categorical, and range-based rule validation.

Example:
    >>> from m02_validation.run_validation_pipeline import run_validation_pipeline
    >>> from m00_utils.config_loader import load_config
    >>> config = load_config("config/run_validation_config.yaml")
    >>> diag_cfg = config.get("diagnostics", {})
    >>> notebook_mode = config.get("notebook", True)
    >>> run_id = config.get("run_id")
    >>> df = run_validation_pipeline(config=config, df=df, notebook=notebook_mode, run_id=run_id)
"""
import logging
import pandas as pd
from analyst_toolkit.m00_utils.load_data import load_csv
from analyst_toolkit.m02_validation.validate_data import run_validation_suite
from analyst_toolkit.m00_utils.export_utils import export_validation_results, save_joblib
from analyst_toolkit.m02_validation.validation_display import display_validation_summary

def configure_logging(notebook: bool = True, logging_mode: str = "auto"):
    if logging_mode == "off": logging.disable(logging.CRITICAL)
    else:
        level = logging.INFO if logging_mode == "on" or not notebook else logging.WARNING
        logging.basicConfig(level=level, format="%(asctime)s - %(levelname)s - %(message)s", force=True)

def run_validation_pipeline(config: dict, notebook: bool = False, df: pd.DataFrame = None, run_id: str = None):
    """
    Executes the validation pipeline with robust configuration handling
    for both standalone and master-runner execution.
    """
    # --- ROBUST CONFIGURATION HANDLING ---
    # If the 'validation' key exists, it means the full config was passed (from master runner).
    # Otherwise, assume the passed config is the correct module-specific block (from notebook).
    if 'validation' in config:
        module_cfg = config.get("validation", {})
    else:
        module_cfg = config

    if not module_cfg:
        raise ValueError("Configuration for 'validation' module not found or is empty.")

    logging_mode = module_cfg.get("logging", "auto")
    configure_logging(notebook=notebook, logging_mode=logging_mode)

    if not run_id: raise ValueError("A 'run_id' must be provided.")
    
    if df is None:
        input_path = module_cfg.get("input_path")
        if not input_path:
            raise KeyError("Missing 'input_path' in validation config and no DataFrame was provided.")
        df = load_csv(input_path)
        logging.info(f"Loaded data from CSV via config: {input_path}")
    else:
        logging.info("Using passed-in DataFrame (no reload).")

    schema_validation_cfg = module_cfg.get("schema_validation", {})
    if schema_validation_cfg.get("run", False):
        validation_results = run_validation_suite(df, config=schema_validation_cfg)

        fail_on_error = schema_validation_cfg.get("fail_on_error", False)
        if fail_on_error:
            failed_checks = [name for name, check in validation_results.items() if isinstance(check, dict) and 'passed' in check and not check.get('passed')]
            if failed_checks:
                error_message = "Validation Gatekeeper FAILED. The following checks did not pass:\n- " + "\n- ".join(failed_checks)
                logging.error(error_message)
                raise ValueError(error_message)
            else:
                logging.info("âœ… Validation Gatekeeper PASSED. All checks are clean.")
        
        settings = module_cfg.get("settings", {})
        if settings.get("export", True):
            export_validation_results(validation_results, config=settings, run_id=run_id)

        if settings.get("show_inline", True) and notebook:
            display_validation_summary(validation_results, notebook=notebook)

        if settings.get("checkpoint", False):
            checkpoint_path = settings.get("checkpoint_path", "").format(run_id=run_id)
            if not checkpoint_path: raise ValueError("Checkpoint enabled but 'checkpoint_path' is missing.")
            save_joblib(df, path=checkpoint_path)

    return df