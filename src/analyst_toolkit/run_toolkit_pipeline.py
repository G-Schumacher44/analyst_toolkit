"""
ðŸš€ run_toolkit_pipeline.py
âœ… Module: Master Pipeline Orchestrator
This is the main entry point for running the entire Analyst Toolkit pipeline from start to finish.

Responsibilities:
- Loads a master YAML configuration file.
- Sequentially executes each enabled module (M01-M10).
- Passes the DataFrame from one module to the next.
- Handles global settings like `run_id` and `notebook_mode`.

Usage (Notebook):
-----------------
```python
from analyst_toolkit.run_toolkit_pipeline import run_full_pipeline

final_df = run_full_pipeline(config_path="config/run_toolkit_config.yaml")
```
Usage (CLI / Script):
---------------------
Ensure `notebook: false` and `run_id: "your_id"` are set in the config YAML.

```bash
python -m analyst_toolkit.run_toolkit_pipeline --config config/run_toolkit_config.yaml
```

"""

import argparse
import logging

import pandas as pd

from analyst_toolkit.m00_utils.config_loader import load_config
from analyst_toolkit.m00_utils.load_data import load_csv

# Import all module runners
from analyst_toolkit.m01_diagnostics.run_diag_pipeline import run_diag_pipeline
from analyst_toolkit.m02_validation.run_validation_pipeline import run_validation_pipeline
from analyst_toolkit.m03_normalization.run_normalization_pipeline import run_normalization_pipeline
from analyst_toolkit.m04_duplicates.run_dupes_pipeline import run_duplicates_pipeline
from analyst_toolkit.m05_detect_outliers.run_detection_pipeline import (
    run_outlier_detection_pipeline,
)
from analyst_toolkit.m06_outlier_handling.run_handling_pipeline import run_outlier_handling_pipeline
from analyst_toolkit.m07_imputation.run_imputation_pipeline import run_imputation_pipeline
from analyst_toolkit.m10_final_audit.final_audit_pipeline import run_final_audit_pipeline

logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")


def run_full_pipeline(config_path: str):
    """
    Executes the full data processing pipeline by chaining modules together.
    """
    logging.info(f"--- Loading Master Orchestration Config from {config_path} ---")
    master_config = load_config(config_path)

    run_id = master_config.get("run_id", "default_run")
    notebook_mode = master_config.get("notebook", False)
    modules_to_run = master_config.get("modules", {})

    # --- ROBUST INITIAL DATA LOAD ---
    entry_path = master_config.get("pipeline_entry_path")
    if not entry_path:
        raise ValueError("Master config is missing 'pipeline_entry_path'. Cannot start pipeline.")

    logging.info(f"--- ðŸšš Loading initial data from {entry_path} ---")
    df: pd.DataFrame = load_csv(entry_path)

    # Initialize artifact placeholder for outlier detection
    detection_results = {}

    # --- MODULE EXECUTION CHAIN ---

    # M01: Diagnostics
    module_info = modules_to_run.get("diagnostics")
    if module_info and module_info.get("run"):
        logging.info("--- ðŸš€ Starting Module: DIAGNOSTICS ---")
        module_config = load_config(module_info["config_path"])
        # The runner function does not modify the df, so no reassignment needed
        run_diag_pipeline(config=module_config, df=df, notebook=notebook_mode, run_id=run_id)
        logging.info("--- âœ… Finished Module: DIAGNOSTICS ---")

    # M02: Initial Validation
    module_info = modules_to_run.get("validation")
    if module_info and module_info.get("run"):
        logging.info("--- ðŸš€ Starting Module: VALIDATION ---")
        module_config = load_config(module_info["config_path"])
        df = run_validation_pipeline(
            config=module_config, df=df, notebook=notebook_mode, run_id=run_id
        )
        logging.info("--- âœ… Finished Module: VALIDATION ---")

    # M03: Normalization
    module_info = modules_to_run.get("normalization")
    if module_info and module_info.get("run"):
        logging.info("--- ðŸš€ Starting Module: NORMALIZATION ---")
        module_config = load_config(module_info["config_path"])
        df = run_normalization_pipeline(
            config=module_config, df=df, notebook=notebook_mode, run_id=run_id
        )
        logging.info("--- âœ… Finished Module: NORMALIZATION ---")

    # M04: Validation Gatekeeper
    module_info = modules_to_run.get("validation_gatekeeper")
    if module_info and module_info.get("run"):
        logging.info("--- ðŸš€ Starting Module: VALIDATION_GATEKEEPER ---")
        module_config = load_config(module_info["config_path"])
        df = run_validation_pipeline(
            config=module_config, df=df, notebook=notebook_mode, run_id=run_id
        )
        logging.info("--- âœ… Finished Module: VALIDATION_GATEKEEPER ---")

    # M05: Duplicates Handling
    module_info = modules_to_run.get("duplicates")
    if module_info and module_info.get("run"):
        logging.info("--- ðŸš€ Starting Module: DUPLICATES ---")
        module_config = load_config(module_info["config_path"])
        df = run_duplicates_pipeline(
            config=module_config, df=df, notebook=notebook_mode, run_id=run_id
        )
        logging.info("--- âœ… Finished Module: DUPLICATES ---")

    # M06: Outlier Detection
    module_info = modules_to_run.get("outlier_detection")
    if module_info and module_info.get("run"):
        logging.info("--- ðŸš€ Starting Module: OUTLIER_DETECTION ---")
        module_config = load_config(module_info["config_path"])
        df, detection_results = run_outlier_detection_pipeline(
            config=module_config, df=df, notebook=notebook_mode, run_id=run_id
        )
        logging.info("--- âœ… Finished Module: OUTLIER_DETECTION ---")

    # M07: Outlier Handling
    module_info = modules_to_run.get("outlier_handling")
    if module_info and module_info.get("run"):
        if not detection_results:
            raise RuntimeError(
                "M07 Outlier Handling cannot run because M06 Outlier Detection did not return results."
            )
        logging.info("--- ðŸš€ Starting Module: OUTLIER_HANDLING ---")
        module_config = load_config(module_info["config_path"])
        df = run_outlier_handling_pipeline(
            config=module_config,
            df=df,
            detection_results=detection_results,
            notebook=notebook_mode,
            run_id=run_id,
        )
        logging.info("--- âœ… Finished Module: OUTLIER_HANDLING ---")

    # M08: Imputation
    module_info = modules_to_run.get("imputation")
    if module_info and module_info.get("run"):
        logging.info("--- ðŸš€ Starting Module: IMPUTATION ---")
        module_config = load_config(module_info["config_path"])
        df = run_imputation_pipeline(
            config=module_config, df=df, notebook=notebook_mode, run_id=run_id
        )
        logging.info("--- âœ… Finished Module: IMPUTATION ---")

    # M10: Final Audit
    module_info = modules_to_run.get("final_audit")
    if module_info and module_info.get("run"):
        logging.info("--- ðŸš€ Starting Module: FINAL_AUDIT ---")
        module_config = load_config(module_info["config_path"])
        df = run_final_audit_pipeline(
            config=module_config, df=df, run_id=run_id, notebook=notebook_mode
        )
        logging.info("--- âœ… Finished Module: FINAL_AUDIT ---")

    logging.info("--- ðŸŽ‰ Full Pipeline Execution Complete ---")
    return df


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Run the full analyst_toolkit data processing pipeline."
    )
    parser.add_argument(
        "--config",
        type=str,
        default="config/run_toolkit_config.yaml",
        help="Path to the master run_toolkit_config.yaml file.",
    )
    args = parser.parse_args()

    run_full_pipeline(config_path=args.config)
